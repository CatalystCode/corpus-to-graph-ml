{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Slow version of gensim.models.word2vec is being used\n",
      "WARNING:gensim.models.doc2vec:Slow version of gensim.models.doc2vec is being used\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./packages\")\n",
    "\n",
    "import matplotlib\n",
    "import datetime\n",
    "import numpy as np\n",
    "import data_preparation_tools as dpt\n",
    "import features_generation_tools as fgt\n",
    "import model_tools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating bow_1_gram features for 9_18_2016_binary_data_entities_normalize\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_1_gram, logistic regression l1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_1_gram, lr l1 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_1_gram, lr l2 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00         4\n",
      "\n",
      "generating bow_2_gram features for 9_18_2016_binary_data_entities_normalize\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_2_gram, logistic regression l1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_2_gram, lr l1 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_2_gram, lr l2 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00         4\n",
      "\n",
      "generating bow_3_gram features for 9_18_2016_binary_data_entities_normalize\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_3_gram, logistic regression l1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_3_gram, lr l1 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_3_gram, lr l2 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00         4\n",
      "\n",
      "generating bow_1_3_gram features for 9_18_2016_binary_data_entities_normalize\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_1_3_gram, logistic regression l1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_1_3_gram, lr l1 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, bow_1_3_gram, lr l2 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00         4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generating doc2vec features for 9_18_2016_binary_data_entities_normalize\n",
      "creating temp file...\n",
      "creating model...\n",
      "model built\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, doc2vec, logistic regression l1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, doc2vec, lr l1 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, doc2vec, lr l2 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       1.00      0.75      0.86         4\n",
      "\n",
      "generating pos_3_3 features for 9_18_2016_binary_data_entities_normalize\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, pos_3_3, logistic regression l1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, pos_3_3, lr l1 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.00      0.00      0.00         4\n",
      "\n",
      "model evaluation for: 9_18_2016_binary_data_entities_normalize, pos_3_3, lr l2 cv\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.50      0.67         4\n",
      "\n",
      "avg / total       1.00      0.50      0.67         4\n",
      "\n",
      "generating bow_1_3_pos_3_3 features for 9_18_2016_binary_data_entities_normalize\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a55ce39aca86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_gen_features_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_features_methods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluation_methods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mrunTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\CatalystCode\\corpus-to-graph-ml\\packages\\features_generation_tools.pyc\u001b[0m in \u001b[0;36mrun_gen_features_pipeline\u001b[1;34m(input_dir, gen_features_methods, evaluation_methods)\u001b[0m\n\u001b[0;32m    319\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mtrain_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_features_and_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevaluation_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\CatalystCode\\corpus-to-graph-ml\\packages\\features_generation_tools.pyc\u001b[0m in \u001b[0;36mgen_features_and_classes\u001b[1;34m(train_test_data, gen_features_func)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[0mtest_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_to_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multiclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_multiclass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_features_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mTrainTestData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_multiclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-a55ce39aca86>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x_train, x_test)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGenFeaturesMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"doc2vec\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_doc2vec_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_doc2vec_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_samples_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGenFeaturesMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pos_3_3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pos_bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGenFeaturesMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bow_1_3_pos_3_3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_bow_and_pos_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGenFeaturesMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bow_1_3_doc2vec\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mfgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_compound_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbow_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc2vec_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m ]\n",
      "\u001b[1;32mc:\\Github\\CatalystCode\\corpus-to-graph-ml\\packages\\features_generation_tools.pyc\u001b[0m in \u001b[0;36mget_bow_and_pos_features\u001b[1;34m(train_samples, test_samples, ngram_range, pos_ngram_range)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_bow_and_pos_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_ngram_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[0mbow_train_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbow_test_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_bow_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m     \u001b[0mpos_train_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_test_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_pos_bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_ngram_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "# path used to save temporary doc2vec files\n",
    "temp_doc2vec_file = r\"./demo_output/temp_doc2vec.txt\"\n",
    "# path to text file that contains background sentences used in doc2vec\n",
    "background_samples_file_path = r\"./demo_output/background_samples.txt\"\n",
    "\n",
    "doc2vec_func = lambda x_train,x_test : fgt.get_doc2vec_features(x_train, x_test, temp_doc2vec_file, background_samples_file_path)\n",
    "bow_func = lambda x_train,x_test : fgt.get_bow_features(x_train, x_test, (1,3))\n",
    "\n",
    "# evaluate different features\n",
    "gen_features_methods = [\n",
    "fgt.GenFeaturesMethod(\"bow_1_gram\", lambda x_train,x_test : fgt.get_bow_features(x_train, x_test, (1,1))),\n",
    "fgt.GenFeaturesMethod(\"bow_2_gram\", lambda x_train,x_test : fgt.get_bow_features(x_train, x_test, (2,2))),\n",
    "fgt.GenFeaturesMethod(\"bow_3_gram\", lambda x_train,x_test : fgt.get_bow_features(x_train, x_test, (3,3))),\n",
    "fgt.GenFeaturesMethod(\"bow_1_3_gram\", lambda x_train,x_test : fgt.get_bow_features(x_train, x_test, (1,3))),\n",
    "fgt.GenFeaturesMethod(\"doc2vec\", lambda x_train,x_test : fgt.get_doc2vec_features(x_train, x_test, temp_doc2vec_file, background_samples_file_path)),\n",
    "fgt.GenFeaturesMethod(\"pos_3_3\", lambda x_train,x_test : fgt.to_pos_bow(x_train, x_test, (3,3))),\n",
    "fgt.GenFeaturesMethod(\"bow_1_3_pos_3_3\", lambda x_train,x_test : fgt.get_bow_and_pos_features(x_train, x_test, (1,3), (3,3))),\n",
    "fgt.GenFeaturesMethod(\"bow_1_3_doc2vec\", lambda x_train,x_test : fgt.get_compound_features(x_train, x_test, [bow_func, doc2vec_func]))\n",
    "]\n",
    "\n",
    "#Cs= [0.005, 0.01, 0.03, 0.05, 0.1, 0.3, 0.5, 0.8] + np.linspace(1,5, 9).tolist()\n",
    "Cs = np.linspace(0.005,0.25,10)\n",
    "\n",
    "# evaluates different classifiers\n",
    "evaluation_methods = [\n",
    "    fgt.EvaluationMethod(\"logistic regression l1\", lambda: LogisticRegression(C=0.1, penalty='l1', solver='liblinear')),\n",
    "    fgt.EvaluationMethod(\"lr l1 cv\", lambda: LogisticRegressionCV(penalty='l1', cv=5, scoring=make_scorer(f1_score), solver='liblinear', Cs=Cs, refit=True)),\n",
    "    fgt.EvaluationMethod(\"lr l2 cv\", lambda: LogisticRegressionCV(penalty='l2', cv=5, scoring=make_scorer(f1_score), solver='liblinear', Cs=Cs, refit=True)),\n",
    "    #fgt.EvaluationMethod(\"GBC\", lambda: GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=10, random_state=0))\n",
    "]\n",
    "\n",
    "# path to input dir \n",
    "input_dir = r\"./demo_output\"\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "models = fgt.run_gen_features_pipeline(input_dir, gen_features_methods, evaluation_methods)\n",
    "\n",
    "runTime = datetime.datetime.now() - startTime\n",
    "print \"Finished generating features, took:%s\"%runTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = models[0]\n",
    "\n",
    "av = [np.average(m.scores_[1][:,i]) for i in xrange(len(m.scores_[1][0])) ]\n",
    "plt.plot(Cs, av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file path to data with test sentences\n",
    "test_file_path = r\"\"\n",
    "\n",
    "# path to context file path which contains the entities for each sentence as well (produced by the data transofrmation pipeline)\n",
    "context_file_path = r\"\"\n",
    "\n",
    "entities_1 = []\n",
    "entities_2 = []\n",
    "\n",
    "with open(context_file_path) as handle:\n",
    "    for l in handle:\n",
    "        parts = l.rstrip().split(\"\\t\")\n",
    "        entities_1.append(parts[0])\n",
    "        entities_2.append(parts[1])\n",
    "\n",
    "sentences, labels = fgt.read_data_from_file(test_file_path)\n",
    "\n",
    "import heapq\n",
    "import PrettyTable as pt\n",
    "\n",
    "COLUMN_NAMES = [\"score\", \"text\", \"Entity 1\", \"Entity2\"]\n",
    "\n",
    "er = models[0]\n",
    "\n",
    "neg_scores = [er.scores[i][0] for i in xrange(len(er.scores))]\n",
    "pos_scores = [er.scores[i][1] for i in xrange(len(er.scores))]\n",
    "\n",
    "\n",
    "def get_top_scoring(scores, sentences, entities_1, entities_2, n):\n",
    "    table_data = []\n",
    "    #scores_arr = np.array(scores)\n",
    "    #l = scores_arr.argsort()[-n:][::-1]\n",
    "    l = heapq.nlargest(n, range(len(scores)), scores.__getitem__)\n",
    "    for i in l:\n",
    "        table_data.append([\"%0.7f\"%scores[i], sentences[i], entities_1[i], entities_2[i]])\n",
    "    return table_data\n",
    "\n",
    "def write_results_to_file(file_path, column_names, table_data):\n",
    "    with open(file_path, \"w\") as handle:\n",
    "        handle.write(\"\\t\".join(COLUMN_NAMES) + \"\\n\")\n",
    "        for l in table_data:\n",
    "            handle.write(\"\\t\".join(l) + \"\\n\")\n",
    "\n",
    "# path to the file that will contain scored sentences, ordered by their score\n",
    "top_scoring_positive_class_file_path = r\"./demo_output/top_scoring_positive_class.txt\"            \n",
    "\n",
    "write_results_to_file(top_scoring_positive_class_file_path, COLUMN_NAMES, get_top_scoring(pos_scores, sentences, entities_1, entities_2, len(pos_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
